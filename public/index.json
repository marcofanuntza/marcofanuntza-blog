[{"content":"Automatic for the people è un album dei R.E.M. mi è venuto in mente quando ho pensato che Ansible è un prodotto di \u0026ldquo;automation\u0026rdquo; IT.\nAnsible è una potente e flessibile piattaforma di automazione IT progettata per semplificare e automatizzare una vasta gamma di compiti, processi e operazioni legate all\u0026rsquo;infrastruttura e allo sviluppo del software.\nDi seguito alcuni aspetti salienti:\nAnsible si distingue per la sua facilità d\u0026rsquo;uso, grazie a una sintassi dichiarativa basata su YAML è accessibile anche a chi ha una conoscenza limitata della programmazione.\nAnsible opera tramite connessioni SSH, eliminando la necessità di installare agenti o client aggiuntivi sulle macchine di destinazione.\nAnsible consente di definire la configurazione di un\u0026rsquo;intera infrastruttura (Infrastracture as a Code) attraverso un semplice file di testo, migliorandone riproducibilità e versioning.\nOltre alla gestione delle configurazioni può automatizzare una vasta gamma di operazioni inclusi il rilascio di applicazioni, il monitoraggio e la scalabilità.\nAnsible è progettato per funzionare su diverse piattaforme e sul cloud, offrendo flessibilità e portabilità.\nAnsible inoltre è in grado di gestire ambienti di varie dimensioni, rendendolo adatto per piccoli progetti fino a progetti più articolati e complessi.\nNel mio ambito lavorativo Ansible era da un pò che ne sentivo parlare ma personalmente non avevo mai avuto modo di utilizzarlo, con questo post sul mio blog unisco l\u0026rsquo;utile al dilettevole cogliendo l\u0026rsquo;occasione per conoscerlo meglio!\nPartiamo dalla basi prima di tutto installandolo, eseguirò i test su una VM con distribuzione Ubuntu 22-04, ansible e i relativi moduli python verranno installati tramite APT\n#Installo ansible sudo add-apt-repository --yes --update ppa:ansible/ansible sudo apt install ansible-core #Verifico la versione installata sudo ansible --version ansible [core 2.15.8] config file = /etc/ansible/ansible.cfg configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules'] ansible python module location = /usr/lib/python3/dist-packages/ansible ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections executable location = /usr/bin/ansible python version = 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0] (/usr/bin/python3) jinja version = 3.0.3 libyaml = True Adesso che Ansible è installato dobbiamo avere a disposizione dei server o delle VM con cui utilizzarlo, per fare questo io personalmente ho creato 3 istanze LXC sul mio cluster Proxmox, anche in questo caso la distribuzione utilizzata è ubuntu, giusto a titolo d\u0026rsquo;esempio qualsiasi altra distribuzione linux andrebbe bene.\nQuesto è il recap delle macchine che ho a disposizione:\nans-serv-01 192.168.1.149\nans-serv-02 192.168.1.150\nans-serv-03 192.168.1.154\nOra i punti cardine principali di Ansible sono i file di configurazione \u0026ldquo;inventario\u0026rdquo; e \u0026ldquo;playbook\u0026rdquo;\nIl file inventario di Ansible contiene informazioni su tutti gli host che Ansible andrà a gestire, in questo file si ha la possibilità di organizzare gli host in diversi gruppi in base ai loro ruoli o funzioni, come ad esempio web-server, database, server di frontend, oppure possiamo categorizzarli in base al sistema operativo. Il file in questione lo troviamo nel path /etc/ansible ed\u0026rsquo;è chiamato hosts, andando a editarlo scoprirete che in parte è già strutturato per aiutarne la comprensione, basterà quindi eliminare i commenti e adattarlo a piacimento.\nNoi in questo esempio andiamo a editarlo così per questa sola parte\n[webservers] ## alpha.example.org ## beta.example.org 192.168.1.149 192.168.1.150 192.168.1.154 come potete intuire sono gli IP delle macchine elencate in precedenza, le ho inserite nel gruppo \u0026ldquo;webserver\u0026rdquo;. Verifichiamo con il comando seguente\nsudo ansible-inventory --list -y all: children: webservers: hosts: 192.168.1.149: {} 192.168.1.150: {} 192.168.1.154: {} Come annunciato in precedenza Ansible non utilizza client o agent all\u0026rsquo;interno dei server da gestire ma si avvale della sola connessione SSH, per utilizzarla però deve essere in grado di connettersi sui server di destinazione, per fare questo è necessario copiare la chiave SSH dal server Ansible verso i server da gestire. Questo inoltre eviterà di dover utilizzare la passwd per connettersi che andrebbe a inficiare sull\u0026rsquo;automatismo non rendendolo possibile\nIniziamo con creare la chiave sul server Ansible\n#Date sempre invio dopo il comando sudo ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa Your public key has been saved in /root/.ssh/id_rsa.pub The key fingerprint is: SHA256:ZRAsk+qjBjQjpsLdEF39qdUmOa5ARx7QPFr6EEQhbDY root@ubuntu-22-04-lts The key's randomart image is: +---[RSA 3072]----+ | o.+OO. | | . E=..X | | +..oB * + | |.= .. = = B o | |* +.o . S + + | |+. .o. . o . | |.. . . . . | | o . | | . | +----[SHA256]-----+ la chiave pubblica adesso va copiata sui server da gestire, il comando che segue va eseguito su tutti e tre i server, la password andrà inserita la prima volta.\nsudo ssh-copy-id root@192.168.1.149 sudo ssh-copy-id root@192.168.1.150 sudo ssh-copy-id root@192.168.1.154 Verifichiamo il buon esito eseguendo questo comando\nsudo ansible all -m ping -u root 192.168.1.149 | SUCCESS =\u0026gt; { \u0026quot;ansible_facts\u0026quot;: { \u0026quot;discovered_interpreter_python\u0026quot;: \u0026quot;/usr/bin/python3\u0026quot; }, \u0026quot;changed\u0026quot;: false, \u0026quot;ping\u0026quot;: \u0026quot;pong\u0026quot; } 192.168.1.150 | SUCCESS =\u0026gt; { \u0026quot;ansible_facts\u0026quot;: { \u0026quot;discovered_interpreter_python\u0026quot;: \u0026quot;/usr/bin/python3\u0026quot; }, \u0026quot;changed\u0026quot;: false, \u0026quot;ping\u0026quot;: \u0026quot;pong\u0026quot; } 192.168.1.154 | SUCCESS =\u0026gt; { \u0026quot;ansible_facts\u0026quot;: { \u0026quot;discovered_interpreter_python\u0026quot;: \u0026quot;/usr/bin/python3\u0026quot; }, \u0026quot;changed\u0026quot;: false, \u0026quot;ping\u0026quot;: \u0026quot;pong\u0026quot; } Adesso Ansible è pronto!\nDopo il file inventario adesso è il momento di mettere mano al file \u0026ldquo;playbook\u0026rdquo;. Rispetto al file inventario che definisce le macchine nel concetto, passatemi il termine hardware, nel file playbook invece vengono definiti gli aspetti software, quindi si andranno a dichiarare tutti gli elementi software e correlati.\nNel nostro esempio abbiamo deciso di installare Nginx, il nostro primo file playbook quindi sarà: /etc/ansible/nginx-playbook.yml\nEcco il contenuto, è un\u0026rsquo;esempio trovato in rete\n--- - hosts: webservers tasks: - ping: ~ - name: Update APT package manager repositories cache become: true apt: update_cache: yes - name: Upgrade installed packages become: true apt: upgrade: safe - name: Install Nginx web server become: true apt: name: nginx state: latest riuscite a intuire che operazioni eseguirà? dai è semplice e mi raccomando prestate attenzione all\u0026rsquo;identazione del file, è YAML lo sai\u0026hellip;.\nSiamo pronti per provare il nostro primo playbook, per eseguirlo utilizzeremo questo comando semplice e basilare\nsudo ansible-playbook nginx-playbook.yml Ecco l\u0026rsquo;output che riceveremo\nPLAY [webservers] ****************************************************************************************************************************************************** TASK [Gathering Facts] ************************************************************************************************************************************************* ok: [192.168.1.154] ok: [192.168.1.150] ok: [192.168.1.149] TASK [ping] ************************************************************************************************************************************************************ ok: [192.168.1.154] ok: [192.168.1.150] ok: [192.168.1.149] TASK [Update APT package manager repositories cache] ******************************************************************************************************************* changed: [192.168.1.150] changed: [192.168.1.154] changed: [192.168.1.149] TASK [Upgrade installed packages] ************************************************************************************************************************************** ok: [192.168.1.150] ok: [192.168.1.154] ok: [192.168.1.149] TASK [Install Nginx web server] **************************************************************************************************************************************** changed: [192.168.1.149] changed: [192.168.1.154] changed: [192.168.1.150] PLAY RECAP ************************************************************************************************************************************************************* 192.168.1.149 : ok=5 changed=2 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 192.168.1.150 : ok=5 changed=2 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 192.168.1.154 : ok=5 changed=2 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Grande Giove!\nEntriamo in uno dei server e verifichiamo la presenza di Nginx\nssh root@192.168.1.154 Welcome to Ubuntu 23.10 (GNU/Linux 6.5.11-7-pve x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/pro Last login: Fri Jan 19 15:37:04 2024 from 192.168.1.147 root@ans-serv-03:~# ps -ef | grep nginx root 1181 1 0 15:37 ? 00:00:00 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; www-data 1183 1181 0 15:37 ? 00:00:00 nginx: worker process root 1241 1231 0 15:44 pts/3 00:00:00 grep --color=auto nginx E\u0026rsquo; tutto vero! Eh si è!\nBuon Ansible a tutti! Questo articolo termina quì, è solo un semplice esempio di quanto sia in grado di fare questo grande strumento di automazione, l\u0026rsquo;unico peccato è non averlo utilizzato prima!\n","permalink":"https://marcofanuntza.it/posts/automazione-con-ansible/","summary":"Automatic for the people è un album dei R.E.M. mi è venuto in mente quando ho pensato che Ansible è un prodotto di \u0026ldquo;automation\u0026rdquo; IT.\nAnsible è una potente e flessibile piattaforma di automazione IT progettata per semplificare e automatizzare una vasta gamma di compiti, processi e operazioni legate all\u0026rsquo;infrastruttura e allo sviluppo del software.\nDi seguito alcuni aspetti salienti:\nAnsible si distingue per la sua facilità d\u0026rsquo;uso, grazie a una sintassi dichiarativa basata su YAML è accessibile anche a chi ha una conoscenza limitata della programmazione.","title":"Automazione con Ansible"},{"content":"Rancher come eseguire un reset della password dell\u0026rsquo;utente Admin\nSi può capitare a tutti di dimenticare una password, ad alcuni spesso, ma niente paura possiamo eseguire un reset eseguendo questi semplici comandi che seguono..\nL\u0026rsquo;esempio che segue mostra come eseguire il reset della password dell\u0026rsquo;utente admin di Rancher installato all\u0026rsquo;interno di un cluster Kubernetes, le operazioni in parte sono valide anche nel caso il vostro Rancher fosse stato installato su un semplice container docker.\nPrerequisiti\navere accesso al cluster Kubernetes tramite kubectl avere accesso al server che esegue docker (nel secondo caso) Procedura\nTramite kubectl individuiamo il pod che sta erogando il servizio Rancher\nkubectl get pods -n cattle-system | grep Running rancher-webhook-7476c74c6c-scbvs 1/1 Running 0 42m rancher-7484b7b4c5-jb9dt 1/1 Running 0 42m a questo punto dobbiamo entrare all\u0026rsquo;interno della console del pod rancher-7484b7b4c5-jb9dt, per farlo eseguiremo\nkubectl exec --stdin --tty rancher-7484b7b4c5-jb9dt -n cattle-system -- /bin/bash noterete che il prompt dei comandi sarà cambiato, siamo all\u0026rsquo;interno del pod e possiamo eseguire dei comandi diretti, quello specifico che farà al caso nostro è un semplice \u0026ldquo;reset password\u0026rdquo;\nreset-password New password for default admin user (user-m258d): tQXngoMxYBtugFp4Xcjg dopo aver copiato la password potete uscire dalla console con \u0026ldquo;exit\u0026rdquo;.\nCon questi semplici passaggi la vostra password admin è stata rigenereata e sarete nuovamente in grado di accedere al vostro Rancher con utenza admin!\n","permalink":"https://marcofanuntza.it/posts/reset-password-admin-rancher/","summary":"Rancher come eseguire un reset della password dell\u0026rsquo;utente Admin\nSi può capitare a tutti di dimenticare una password, ad alcuni spesso, ma niente paura possiamo eseguire un reset eseguendo questi semplici comandi che seguono..\nL\u0026rsquo;esempio che segue mostra come eseguire il reset della password dell\u0026rsquo;utente admin di Rancher installato all\u0026rsquo;interno di un cluster Kubernetes, le operazioni in parte sono valide anche nel caso il vostro Rancher fosse stato installato su un semplice container docker.","title":"Reset password utente admin su Rancher"},{"content":"Kubernetes è un sistema di gestione (orchestratore) di container che è diventato di fatto lo standard per distribuire applicazioni containerizzate.\nQuesto perché Kubernetes è potente, affidabile, flessibile e per lo più facile da usare (come no).\nSi facile da utilizzare dopo che si supera il primo scoglio iniziale..\nIo personalmente ho avuto difficoltà nel visualizzare mentalmente il cluster e tutti i componenti che ne facevano parte utilizzando solo gli strumenti della riga di comando finché non ho familiarizzato con la sua struttura.\nPer fare ciò è stato di grandissimo aiuto (per me) l\u0026rsquo;utilizzo di Rancher!\nCon questo articolo spero di aiutare tutti gli interessati che vogliono conoscere e sperimentare Kubernetes, il risultato finale di questa guida vi permetterà di avere una sorta di laboratorio sulla vostra workstation/server e toccare con mano un cluster Kubernetes.\nPer raggiungere le scopo verranno installati i seguenti elementi:\nDocker: Il sistema più diffuso per gestire container\nKubectl: Strumento a riga di comando utilizzato per controllare il cluster Kubernetes\nHelm: Gestore di pacchetti per Kubernetes. Consente di installare, aggiornare e gestire applicazioni su un cluster Kubernetes.\nK3d: k3d è un progetto guidato dalla community, supportato da Rancher (SUSE). È un wrapper per eseguire k3s in Docker.\nK3s: È una distribuzione Kubernetes pronta per la produzione, molto leggera, sviluppata da Rancher.\nRancher: Banalmente potrebbe essere considerata una GUI per Kubernetes ma fa molto di più! Permette di gestire e configurare più cluster Kubernetes da un unico punto di controllo.\nPremessa\navere a disposizione una workstation o server con distribuzione Linux (si potrebbe utilizzare anche WSL2 su Windows ma non lo tratteremo in questo articolo) accesso alla rete per scaricare pacchetti Procedura parte 1\nQui procediamo con installazione degli elementi Docker, K3D, Helm e Kubectl\nDocker\n# Aggiungiamo la chiave **GPG key** ufficiale del repository Docker sudo apt-get update sudo apt-get install ca-certificates curl gnupg sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg echo \u0026quot;deb [arch=\u0026quot;$(dpkg --print-architecture)\u0026quot; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \u0026quot;$(. /etc/os-release \u0026amp;\u0026amp; echo \u0026quot;$VERSION_CODENAME\u0026quot;)\u0026quot; stable\u0026quot; | sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io K3D\nsudo wget -q -O - https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | bash Helm\nsudo curl -s https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash Kubectl\nsudo curl -LO \u0026quot;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026quot; sudo chmod +x kubectl sudo mv kubectl /usr/local/bin Procedura parte 2\nAdesso procederemo con la creazione del cluster Kubernetes tramite K3D utilizzando K3S e infine completeremo installando Rancher tramite Helm.\nCreazione cluster Kubernetes\nsudo k3d cluster create k8s-test-rancher -p \u0026quot;8900:30080@agent:0\u0026quot; -p \u0026quot;8901:30081@agent:0\u0026quot; -p \u0026quot;8902:30082@agent:0\u0026quot; --agents 2 Il comando andrà a creare un cluster chiamato \u0026ldquo;k8s-test-rancher\u0026rdquo; con 3 porte esposte: 30080, 30081 e 30082. Verranno mappate rispettivamente alle porte 8900, 8901 e 8902 della workstation o server che state utilizzando. Il cluster saà composto da 1 nodo master e 2 nodi worker.\nOra facciamo in modo che Kubectl conosca il file di configurazione del cluster eseguendo il seguente comando\nsudo k3d kubeconfig merge k8s-test-rancher --kubeconfig-switch-context Eseguiamo ora una prima verifica della presenza del cluster e dei nodi elencati\nsudo kubectl get nodes Se tutto procede come dovrebbe dovreste avere lo stesso risultato di sotto\nNAME STATUS ROLES AGE VERSION k3d-k8s-test-rancher-server-0 Ready control-plane,master 36s v1.27.4+k3s1 k3d-k8s-test-rancher-agent-0 Ready \u0026lt;none\u0026gt; 32s v1.27.4+k3s1 k3d-k8s-test-rancher-agent-1 Ready \u0026lt;none\u0026gt; 32s v1.27.4+k3s1 Adesso siamo pronti per l\u0026rsquo;ultimo passaggio fondamentale, installare Rancher tramite Helm\nsudo helm repo add rancher-latest https://releases.rancher.com/server-charts/latest sudo helm install rancher rancher-latest/rancher --namespace cattle-system --create-namespace --set ingress.enabled=false --set tls=external --set replicas=1 Nel frattempo che Helm completerà l\u0026rsquo;installazione, se siete cusiosi potete interagire con il cluster e verificare cosa stia installando\nsudo kubectl get deployment -n cattle-system sudo kubectl get pods -n cattle-system A questo punto dobbiamo metterci nelle condizioni di poter raggiungere Rancher sulla propria web-gui, per farlo è necessario creare un NodePort. Create questo file yaml\nsudo vi rancher.yaml al suo interno incollate questa dichiarazione, che sostanzialmente eseguirà un match con le porte settate in precedenza\napiVersion: v1 kind: Service metadata: labels: app: rancher name: ranchernodeport namespace: cattle-system spec: ports: - name: http nodePort: 30080 port: 80 protocol: TCP targetPort: 80 - name: https nodePort: 30081 port: 443 protocol: TCP targetPort: 443 selector: app: rancher type: NodePort Attenzione è importante sia identato correttamente, dovete rispettare gli spazi, yaml non perdona, lo scoprirete presto :D\nAttiviamo il NodePort eseguendo il comando\nsudo kubectl apply -f rancher.yaml Adesso potete utilizzare il vostro browser e chiamare la seguente url\nhttps://vostroip:8901/dashboard/auth/login Non date importanza al warning sul certificato è perche utilizza un self signed, andate avanti e vi ritroverete la pagina web di Rancher, vi verrà suggerito come recuperare la passwd seguite le indicazioni con il comando kubectl\nBenvenuti su Rancher il vostro cluster Kubernetes è pronto! la guida termina quì, spero sia stata semplice e chiara da seguire!\nps. immagine in copertina creata da Dall-E tramite co-pilot\n","permalink":"https://marcofanuntza.it/posts/proviamo-kubernetes-e-rancher-con-k3d/","summary":"Kubernetes è un sistema di gestione (orchestratore) di container che è diventato di fatto lo standard per distribuire applicazioni containerizzate.\nQuesto perché Kubernetes è potente, affidabile, flessibile e per lo più facile da usare (come no).\nSi facile da utilizzare dopo che si supera il primo scoglio iniziale..\nIo personalmente ho avuto difficoltà nel visualizzare mentalmente il cluster e tutti i componenti che ne facevano parte utilizzando solo gli strumenti della riga di comando finché non ho familiarizzato con la sua struttura.","title":"Proviamo Kubernetes con Rancher"},{"content":"Iniziamo con capire che cos\u0026rsquo;è K3D e non confondiamolo con K3S\nK3D\nK3D è un \u0026ldquo;wrapper\u0026rdquo; che come scrive Wikipedia \u0026ldquo;è un\u0026rsquo;avvolgitore, un modulo software che ne \u0026ldquo;riveste\u0026rdquo; un altro\u0026rdquo; Si la traduzione dall\u0026rsquo;inglese non è felicissima, in questo caso specifico consente di eseguire K3S, che è la distribuzione minimale di Kubernetes sviluppata da Rancher Labs, all\u0026rsquo;interno di Docker.\nIn altre parole, K3D semplifica la creazione e la gestione di cluster Kubernetes leggeri e portatili che utilizzano K3S, rendendo il processo più agevole, specialmente per coloro che sviluppano in locale utilizzando tecnologie Kubernetes.\nÈ importante notare che K3D è un progetto guidato dalla community, non è un prodotto ufficiale di Rancher (SUSE) che ha creato e mantiene K3S. Tuttavia, K3D offre un\u0026rsquo;opzione comoda e flessibile per coloro che desiderano utilizzare K3S all\u0026rsquo;interno di container Docker.\nPrerequisiti\navere a disposizione un server o una VM con distribuzione linux (si può installare anche su Windows o Mac ma non lo tratteremo quì) accesso alla rete per scaricare files curl e/o wget installati avere docker installato, per installarlo vi ricordo un precedente articolo QUI Procedura\nPer installare K3D sostanzialmente si tratterà semplicemente di scaricare uno script bash che si occuperà in totale autonomia dell\u0026rsquo;installazione, abbiamo due alternative, utilizzare curl oppure wget, c\u0026rsquo;è da dire che lo script utilizzerà curl per scaricare i files quindi curl dovete installarlo comunque.\nsudo apt install curl -y sudo wget -q -O - https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | bash oppure tramite curl\nsudo curl -s https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | bash Attendete che lo script completi e poi verificatene il risultato con\nk3d version k3d version v5.6.0 k3s version v1.27.4-k3s1 (default) Ora che K3D è installato possiamo provare a creare il nostro primo cluster Kubernetes (K3S) eseguendo questo comando\nsudo k3d cluster create mycluster Attendete il completamento, nel mio caso ha completato in poco più di 30 secondi\nINFO[0000] Prep: Network INFO[0000] Created network 'k3d-mycluster' INFO[0000] Created image volume k3d-mycluster-images INFO[0000] Starting new tools node... INFO[0001] Creating node 'k3d-mycluster-server-0' INFO[0001] Pulling image 'ghcr.io/k3d-io/k3d-tools:5.6.0' INFO[0003] Pulling image 'docker.io/rancher/k3s:v1.27.4-k3s1' INFO[0003] Starting Node 'k3d-mycluster-tools' INFO[0011] Creating LoadBalancer 'k3d-mycluster-serverlb' INFO[0012] Pulling image 'ghcr.io/k3d-io/k3d-proxy:5.6.0' INFO[0017] Using the k3d-tools node to gather environment information INFO[0017] HostIP: using network gateway 172.18.0.1 address INFO[0017] Starting cluster 'mycluster' INFO[0017] Starting servers... INFO[0017] Starting Node 'k3d-mycluster-server-0' INFO[0022] All agents already running. INFO[0022] Starting helpers... INFO[0022] Starting Node 'k3d-mycluster-serverlb' INFO[0028] Injecting records for hostAliases (incl. host.k3d.internal) and for 2 network members into CoreDNS configmap... INFO[0030] Cluster 'mycluster' created successfully! INFO[0030] You can now use it like this: kubectl cluster-info Ora come suggerisce l\u0026rsquo;ultima riga dell\u0026rsquo;output, per interagire con il cluster dobbiamo utilizzare kubectl, installiamolo quindi\nsudo curl -LO \u0026quot;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026quot; sudo chmod +x kubectl sudo mv kubectl /usr/local/bin Dobbiamo fare in modo che kubectl conosca il file di configurazione del cluster\nsudo k3d kubeconfig merge mycluster --kubeconfig-switch-context Adesso siamo pronti per interagire con il cluster\nsudo kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME k3d-mycluster-server-0 Ready control-plane,master 12m v1.27.4+k3s1 172.18.0.2 \u0026lt;none\u0026gt; K3s dev 5.15.0-91-generic containerd://1.7.1-k3s1 Come potrete notare il cluster è composto da un unico nodo K3S, ma questo sarà comunque sufficiente per eseguire tutti i test e le esigenze di sviluppo.\nSia comunque ben chiaro che questo è solo un esempio, K3D tramite ulteriori opzioni e file di configurazione vi permette di creare cluster con più nodi. QUI la documentazione ufficiale.\nContinuando a curiosare potete vedere cosa ha installato K3D\nsudo kubectl get svc -A NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default kubernetes ClusterIP 10.43.0.1 \u0026lt;none\u0026gt; 443/TCP 20m kube-system kube-dns ClusterIP 10.43.0.10 \u0026lt;none\u0026gt; 53/UDP,53/TCP,9153/TCP 20m kube-system metrics-server ClusterIP 10.43.151.46 \u0026lt;none\u0026gt; 443/TCP 20m kube-system traefik LoadBalancer 10.43.61.96 172.18.0.2 80:32526/TCP,443:32411/TCP 19m sudo kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system local-path-provisioner-957fdf8bc-g6vsb 1/1 Running 0 20m kube-system coredns-77ccd57875-h6krb 1/1 Running 0 20m kube-system metrics-server-648b5df564-nn5kk 1/1 Running 0 20m kube-system helm-install-traefik-crd-52bfs 0/1 Completed 0 20m kube-system helm-install-traefik-nzmhv 0/1 Completed 1 20m kube-system svclb-traefik-caab8633-t7m98 2/2 Running 0 19m kube-system traefik-64f55bb67d-gnvf8 1/1 Running 0 19m Personalmente conosco anche un altra alternativa per creare velocemente un cluster kubernetes, forse scriverò un prossimo articolo, l\u0026rsquo;alternativa cmq è kind\n","permalink":"https://marcofanuntza.it/posts/come-installare-k3d/","summary":"Iniziamo con capire che cos\u0026rsquo;è K3D e non confondiamolo con K3S\nK3D\nK3D è un \u0026ldquo;wrapper\u0026rdquo; che come scrive Wikipedia \u0026ldquo;è un\u0026rsquo;avvolgitore, un modulo software che ne \u0026ldquo;riveste\u0026rdquo; un altro\u0026rdquo; Si la traduzione dall\u0026rsquo;inglese non è felicissima, in questo caso specifico consente di eseguire K3S, che è la distribuzione minimale di Kubernetes sviluppata da Rancher Labs, all\u0026rsquo;interno di Docker.\nIn altre parole, K3D semplifica la creazione e la gestione di cluster Kubernetes leggeri e portatili che utilizzano K3S, rendendo il processo più agevole, specialmente per coloro che sviluppano in locale utilizzando tecnologie Kubernetes.","title":"Come installare K3D"},{"content":"Premessa\nQuesta guida mostra i comandi da eseguire per creare un template di una VM da utilizzare su Proxmox, la distro utilizzata è Ubuntu e l\u0026rsquo;immagine sarà una versione specifica per il cloud.\nLe Immagini Cloud sono piccole immagini certificate e pronte per il cloud, hanno Cloud Init preinstallato e pronto per accettare una Cloud Config.\nI comandi verranno tutti eseguiti da shell all\u0026rsquo;interno di un nodo Proxmox\nProcedura\nIniziamo scaricando l\u0026rsquo;immagine Ubuntu dalla pagina specifica Ubuntu Cloud Images per questa guida utilizzeremo Ubuntu Server 24.04 LTS (Noble Numbat)\nwget https://cloud-images.ubuntu.com/noble/current/noble-server-cloudimg-amd64.img Creiamo la VM che diventerà la base per il successivo template\nqm create 2000 --memory 2048 --core 2 --name ubuntu-cloud-noble --net0 virtio,bridge=vmbr0 Importiamo l\u0026rsquo;immagine precedentemente scaricata sul volume locale mettendola a disposizione della VM\nqm importdisk 2000 noble-server-cloudimg-amd64.img local-lvm Attendiamo il trasferimento e poi procederemo con collegare il nuovo disco alla VM come un\u0026rsquo;unità SCSI sul controller SCSI\nqm set 2000 --scsihw virtio-scsi-pci --scsi0 local-lvm:vm-2000-disk-0 Adesso aggiungiamo il cloud-init drive, questo è una parte indispensabile per la creazione del template, permette di cambiare la configurazione dell\u0026rsquo;immagine ogni volta che verrà utilizzato il template\nqm set 2000 --ide2 local-lvm:cloudinit Rendiamo l\u0026rsquo;unità cloud-init avviabile e limitiamo i permessi al solo BIOS\nqm set 2000 --boot c --bootdisk scsi0 Aggiungiamo infine serial console\nqm set 2000 --serial0 socket --vga serial0 ATTENZIONE a questo punto non avviate la VM appena creata, siamo pronti per creare il template eseguendo quest\u0026rsquo;ultimo semplice comando\nqm template 2000 Renamed \u0026quot;vm-2000-disk-0\u0026quot; to \u0026quot;base-2000-disk-0\u0026quot; in volume group \u0026quot;pve\u0026quot; Logical volume pve/base-2000-disk-0 changed. WARNING: Combining activation change with other commands is not advised. Adesso avete a disposizione un template che vi permetterà di generare N immagini Ubuntu senza il bisogno di dover ogni volta rieseguire una nuova installazione, insomma è un template!\nChiudiamo la guida con un semplice esempio creando una nuova VM partendo dal template appena creato\nqm clone 2000 110 --name ubuntu-noble-01 --full Verificando possiamo notare la VM appena creata con ID 110 e nome ubuntu-noble-01\nqm list VMID NAME STATUS MEM(MB) BOOTDISK(GB) PID 103 haos11.2 stopped 4096 32.00 0 110 ubuntu-noble-01 stopped 2048 3.50 0 2000 ubuntu-cloud-noble stopped 2048 3.50 0 Noterete anche che l\u0026rsquo;immagine ha un disco di soli 3.5GB, nessun problema in base alle vostre esigenze potete ridimensionare il disco eseguendo questo successivo comando\nqm resize 110 resize scsi0 15G Size of logical volume pve/vm-110-disk-0 changed from 3.50 GiB (896 extents) to 15.00 GiB (3840 extents). Logical volume pve/vm-110-disk-0 successfully resized. Adesso siamo pronti per far partire la nostra nuova VM creata dal template.. ma manca qualcosa, spero i più attenti ci abbiano fatto caso, che user e passwd dobbiamo utilizzare per il login?\nE\u0026rsquo; qui che entra in gioco cloud-init, aprite la web-gui di Proxmox e posizionatevi sulle voci di menù relative alla VM, cliccate sulla voce Cloud-init e noterete le voci che si possono editare, modificatele e provate a far partire la VM.\nPer l\u0026rsquo;accesso tramite SSH da remoto dovete utilizzare direttamente la vostra chiave SSH, si potete inserirla direttamente come sopra.\nLa guida termina qui, se velete utilizzare una distribuzione diversa da Ubuntu niente vi vieta di farlo, la guida va semplicemente adattata utilizzando un\u0026rsquo;immagine diversa.\n","permalink":"https://marcofanuntza.it/posts/come-creare-template-ubuntu-su-proxmox/","summary":"Premessa\nQuesta guida mostra i comandi da eseguire per creare un template di una VM da utilizzare su Proxmox, la distro utilizzata è Ubuntu e l\u0026rsquo;immagine sarà una versione specifica per il cloud.\nLe Immagini Cloud sono piccole immagini certificate e pronte per il cloud, hanno Cloud Init preinstallato e pronto per accettare una Cloud Config.\nI comandi verranno tutti eseguiti da shell all\u0026rsquo;interno di un nodo Proxmox\nProcedura\nIniziamo scaricando l\u0026rsquo;immagine Ubuntu dalla pagina specifica Ubuntu Cloud Images per questa guida utilizzeremo Ubuntu Server 24.","title":"Come creare template Ubuntu su Proxmox"},{"content":"Come installare Docker e Docker compose su Ubuntu\nQuesta guida elenca passo per passo la procedura da seguire per installare docker, docker compose e containerd su distribuzione Ubuntu.\nPrerequisiti:\nserver o workstation con distribuzione ubuntu accesso alla rete per scaricare i pacchetti Procedura\nTutti i comandi verranno eseguiti da terminale, se in precedenza avevate già provato un\u0026rsquo;installazione di Docker sarebbe opportuno rimuoverla eseguendo il comando che segue:\nsudo apt-get purge docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin docker-ce-rootless-extras adesso si può procedere con l\u0026rsquo;installazione, si parte prima di tutto aggiungendo il repository ufficiale Docker\n# Aggiungiamo la chiave **GPG key** ufficiale del repository Docker: sudo apt-get update sudo apt-get install ca-certificates curl gnupg sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg aggiungiamo il repository ufficiale Docker al sistema APT:\necho \\ \u0026quot;deb [arch=\u0026quot;$(dpkg --print-architecture)\u0026quot; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ \u0026quot;$(. /etc/os-release \u0026amp;\u0026amp; echo \u0026quot;$VERSION_CODENAME\u0026quot;)\u0026quot; stable\u0026quot; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update qui il comando per installazione dei pacchetti necessari:\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin verifichiamo le versioni installate di Docker e Docker compose:\ndocker -v docker compose a questo punto possiamo considerare completata l\u0026rsquo;installazione, in via opzionale ci resta solamente abilitare il nostro user per utilizzo del comando docker senza il bisogno di utilizzare ogni volta sudo, per farlo aggiungiamo semplicemente lo user al gruppo docker\nsudo usermod -aG docker $USER that\u0026rsquo;all folks!\n","permalink":"https://marcofanuntza.it/posts/come-installare-docker-e-docker-compose-su-ubuntu/","summary":"Come installare Docker e Docker compose su Ubuntu\nQuesta guida elenca passo per passo la procedura da seguire per installare docker, docker compose e containerd su distribuzione Ubuntu.\nPrerequisiti:\nserver o workstation con distribuzione ubuntu accesso alla rete per scaricare i pacchetti Procedura\nTutti i comandi verranno eseguiti da terminale, se in precedenza avevate già provato un\u0026rsquo;installazione di Docker sarebbe opportuno rimuoverla eseguendo il comando che segue:\nsudo apt-get purge docker-ce docker-ce-cli containerd.","title":"Come installare Docker e Docker Compose su Ubuntu"},{"content":"Questo articolo continua il log partito da QUI dove spiegavo la scelta e il perchè .\nI componenti che attendevo sono arrivati, oltre la lista iniziale ho apportato alcune integrazioni aggiungendo una scheda PCI che di fatto mette a disposizione due porte SATA III aggiuntive. A questa scheda sono direttamente connessi i due dischi da 2,5 pollici, 2TB cadauno. Altra integrazione è un ulteriore banco di ram da 8GB.\nLa prima installazione è abbastanza semplice, se avete già avuto modo di installare una distro linux da pendrive USB sarà una passeggiata. Per creare la pendrive USB bootabile ho utilizzato il software Balena Etcher e la ISO di Truenas Core potete ovviamente trovarla sui repository ufficiali. La procedura guidata vi chiederà su quale disco installare l\u0026rsquo;OS, imposterete una password e successivamente sarà il turno della rete, finito! nel mio caso ha completato l\u0026rsquo;installazione in pochi minuti. A questo link comunque potete seguire la pagina ufficiale con immagini passo per passo.\nOra potete anche scollegare monitor e tastiera dal server, tutto il resto potrà essere eseguito dalla web-gui di Truenas!\nIn questa galleria di immagini seguente potete vedere la dashboard iniziale che presenta con Truens CORE\n.\nPrime operazioni basilari che ho eseguito su TrueNAS CORE\nImpostato default gateway: questo è indispensabile per cercare/installare aggiornamenti e installare plugin jail Impostato DNS: ovviamente, no dns no party Creato primo pool: primo passaggio per inizializzare lo storage a disposizione Le mie esigenze\nIn aggiornamento…..\n","permalink":"https://marcofanuntza.it/2024/01/13/il-mio-nuovo-nas-con-truenas-part2/","summary":"Questo articolo continua il log partito da QUI dove spiegavo la scelta e il perchè .\nI componenti che attendevo sono arrivati, oltre la lista iniziale ho apportato alcune integrazioni aggiungendo una scheda PCI che di fatto mette a disposizione due porte SATA III aggiuntive. A questa scheda sono direttamente connessi i due dischi da 2,5 pollici, 2TB cadauno. Altra integrazione è un ulteriore banco di ram da 8GB.\nLa prima installazione è abbastanza semplice, se avete già avuto modo di installare una distro linux da pendrive USB sarà una passeggiata.","title":"Il mio nuovo NAS con Truenas part II"},{"content":"Introduzione:\nQuando ho deciso di riscrivere sul blog il cms scelto inizialmente era stato Wordpress, per ambito lavorativo avevo già gestito server wordpress decine di volte, avevo avuto anche un\u0026rsquo;esperienza come writer assiduo sul defunto blog actioncamitalia, la scelta quindi si era basata esclusivamente sull\u0026rsquo;esperienza passata. Dopo un pò mi sono accorto però che per le mie esigenze, per le esigenze di questo blog specifico, l\u0026rsquo;utilizzo delle risorse necessarie per worpress erano sprecate, insomma non ne avevo bisogno.\nDa qui è partita la ricerca su un nuovo CMS per il mio blog.\nCi sono molte piattaforme di blogging. Essendo un sistemista, le mie esigenze per una piattaforma di blogging potrebbero differire da quelle della maggior parte dei blogger. Io vorrei che il mio blog sia:\nFacile da mantenere per quanto riguarda gli aggiornamenti del software Semplice nelle sue funzionalità Facile per me da configurare Trasparente su ciò che sta accadendo sotto il cofano Che cos\u0026rsquo;è Hugo?\nHugo è un framework open source per la generazione di siti web statici. Creato utilizzando il linguaggio di programmazione Go (o Golang), Hugo si distingue per la sua velocità straordinaria nella generazione di contenuti statici. Alcune caratteristiche chiave di Hugo includono:\nVelocità: Grazie alla sua implementazione in Go, Hugo è notevolmente veloce nella generazione di siti web statici, rendendo il processo efficiente e immediato.\nSemplicità: Hugo è progettato per essere facile da usare e comprendere. La sua struttura chiara e la documentazione completa facilitano la creazione e la gestione di siti web.\nFlessibilità: Supporta temi e layout personalizzabili, consentendo agli sviluppatori di adattare l\u0026rsquo;aspetto e la struttura del sito secondo le proprie esigenze.\nGenerazione di Contenuti Statici: Hugo crea siti web completamente statici, eliminando la necessità di un server di backend. Ciò li rende sicuri, facili da distribuire e veloci da caricare.\nInstallare Hugo\nSu qualsiasi distribuzione linux è abbastanza semplice installare Hugo, i vari snap, apt e yum hanno nei loro repository i pacchetti necessari, ma c\u0026rsquo;è da dire che spesso non sono aggiornati. Il mio consiglio è scaricarvi il pacchetto più recente e installarlo a manina.\nNel mio caso specifico ho deciso di installare Hugo su un container LXC erogato dal mio cluster Proxmox, distribuzione ho scelto una ubuntu 23-10, dal sito di Hugo ho scaricato l\u0026rsquo;ultima release disponibile del pacchetto deb\nnota. scegliete la versione \u0026ldquo;extended\u0026rdquo;\nwget https://github.com/gohugoio/hugo/releases/download/v0.121.2/hugo_extended_0.121.2_linux-amd64.deb eseguito il comando di installazione:\ndpkg -i hugo_extended_0.121.2_linux-amd64.deb qui il risultato:\nhugo version hugo v0.121.2-6d5b44305eaa9d0a157946492a6f319da38de154+extended linux/amd64 BuildDate=2024-01-05T12:21:15Z VendorInfo=gohugoio Primi Passi\nPrima di tutto vi consiglio di leggere la documentazione di Hugo e consiglio di partire dalla quick-start\nIo non l\u0026rsquo;ho seguita alla lettera ma ho apportato alcune modifiche, procediamo con la creazione del nostro primo sitoweb con Hugo, posizionatevi in un path qualunque sul vostro server e eseguite il seguente comando:\nhugo new site mio-nuovo-blog --format yaml descrivendo nello specifico il comando, la prima parte istruisce hugo per creare un sito, mio-nuovo-blog sarà il nome del sito e l\u0026rsquo;opzione -format yaml farà in modo che i file di configurazione vengano formattati in formato yaml invece che toml, a mio avviso più semplice e intuitivo a prima vista.\nScoprirete che hugo ha creato una nuova directory con il nome del sito e posizionato al suo interno tutti i files necessari, dovreste ritrovarvi in questa simile situazione\nIl passo successivo sarà scegliere e abiltare un tema da utilizzare, date un\u0026rsquo;occhiata sul sito ufficiale e scegliete quello che preferite. Sono quasi tutti ben documentati e la procedura per attivarli è quasi sempre la stessa, sostanzialmente va utilizzato git e scaricato il repository all\u0026rsquo;interno del path creato in precedenza da Hugo.\nIo ho scelto il tema PaperMod e l\u0026rsquo;ho abilitato come submodulo di git con i seguenti comandi:\ngit init questo vi servirà anche nel caso voi decidiate di versionare il vostro sito su GitHub, procediamo poi con:\ngit submodule add --depth=1 https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod git submodule update --init --recursive # needed when you reclone your repo (submodules may not get cloned automatically) Ora troverete il tema installato e a disposizione per il vostro nuovo sito, i files del tema sono posizionati all\u0026rsquo;interno del path themes/PaperMod.\nIl file che editerete principalmente sarà config.yaml, questo è di fatto il punto principale di controllo per il vostro sito Hugo.\nMa finiamo con un\u0026rsquo;ultimo comando poi lascerò a voi il bello di configurarvi il vostro sito Hugo!\nCome creo il mio primo post?\nBene niente di più semplice, per farlo utilizziamo nuovamente un comando hugo\nhugo new content posts/il-mio-primo-post.md questo comando creerà un nuovo post vuoto e come potrete intuire sarà sul path content/posts/\nA questo punto credo sia arrivato il momento di lasciarvi scoprire come andare avanti con Hugo in base alle vostre esigenze, se volete comunque dare un\u0026rsquo;occhiata al codice del mio blog, questo stesso che sta leggendo, vi lascio il link al mio repository su GitHub\nPeace \u0026amp; Love!\n","permalink":"https://marcofanuntza.it/2024/01/12/ho-scelto-hugo/","summary":"Introduzione:\nQuando ho deciso di riscrivere sul blog il cms scelto inizialmente era stato Wordpress, per ambito lavorativo avevo già gestito server wordpress decine di volte, avevo avuto anche un\u0026rsquo;esperienza come writer assiduo sul defunto blog actioncamitalia, la scelta quindi si era basata esclusivamente sull\u0026rsquo;esperienza passata. Dopo un pò mi sono accorto però che per le mie esigenze, per le esigenze di questo blog specifico, l\u0026rsquo;utilizzo delle risorse necessarie per worpress erano sprecate, insomma non ne avevo bisogno.","title":"Ho scelto Hugo!"},{"content":"Che ne sarà di noi mi verrebbe da dire.. oggi stavo continuando con il tuning del nuovo tema Hugo che sto utilizzando e ho notato che è possibile inserire un logo in homepage, quindi ho avuto la brillante idea di chiedere a bing-chat e alla nuova funzione di Microsoft chiamata Co-Pilot di generare per me un\u0026rsquo;immagine logo con l\u0026rsquo;ausilio della intelligenza artificiale. Come avrete potuto già intuire la situazione mi è leggermente sfuggita di mano.\nCo-pilot è un assistente virtuale basato sull’intelligenza artificiale che ti aiuta a svolgere diverse attività con una semplice chat. Puoi chiedere a Co-pilot di suggerirti codici, migliorare la tua scrittura, fornirti informazioni utili e molto altro. Co-pilot è integrato in vari prodotti Microsoft, come Edge, Windows 11, Word, Excel e Teams.\nMicrosoft come suo solito fare ha acquisito DALL-E che è un algoritmo di intelligenza artificiale capace di generare immagini a partire da descrizioni testuali attraverso la sintografia.\nSe anche voi volete provarlo vi basterà utilizzare il browser nativo di Microsoft Edge, cercate Bing Chat, tra i risultati vi verrà proposto di attivare e provare Co-Pilot. Sulla parte destra della pagina apparirà una finestra dove sarà possibile interagire con Co-Pilot, basterà scrivere:\n\u0026quot;Genera immagine che mostra una gatto con lo sfondo di un bosco incantato, il gatto deve essere terrificante\u0026quot; Che esempio del piffero che ho fatto, comunque tutto questo per farvi capire che il vostro unico limite sarà la fantasia!\nA me stranamente invece è venuta idea di creare immagini con ragazze asiatiche con sullo sfondo città Asiatiche. Sawadee Kaaap!\n","permalink":"https://marcofanuntza.it/2024/01/01/pensare-che-cercavo-un-logo/","summary":"Che ne sarà di noi mi verrebbe da dire.. oggi stavo continuando con il tuning del nuovo tema Hugo che sto utilizzando e ho notato che è possibile inserire un logo in homepage, quindi ho avuto la brillante idea di chiedere a bing-chat e alla nuova funzione di Microsoft chiamata Co-Pilot di generare per me un\u0026rsquo;immagine logo con l\u0026rsquo;ausilio della intelligenza artificiale. Come avrete potuto già intuire la situazione mi è leggermente sfuggita di mano.","title":"E pensare che cercavo un logo.."},{"content":"Quanto vi infastidiscono gli annunci pubblicitari navigando sul web? Ormai ci sono pagine web piene di annunci, pop-up fastidiosissimi che non fanno altro che farci perdere tempo e voglia di visitarne il sito, i quotidiani con le news e le notizie sportive su tutti sono i più scassa bit.\nPer fortuna ci viene in aiuto Pi-Hole!\nPi-hole è un software open-source progettato per il controllo e la gestione della rete orientato nello specifico proprio per combattere la pubblicità e gli annunci correlati, sostanzialmente agisce come un filtro DNS, offrendo funzionalità avanzate per bloccare tutti gli annunci pubblicitari, tracker e tutti i contenuti indesiderati ancor prima che raggiungano i nostri dispositivi connessi alla rete.\nCaratteristiche Principali:\nBlocco degli Annunci: Pi-hole utilizza liste di blocco per intercettare le richieste DNS associate agli annunci pubblicitari, consentendo di eliminare la visualizzazione di annunci indesiderati su tutti i dispositivi connessi alla rete.\nFiltro DNS: Attraverso il blocco delle richieste DNS indesiderate, Pi-hole inoltre impedisce l’accesso a siti malevoli contenenti malware o altri contenuti indesiderati, contribuendo a migliorare la sicurezza della navigazione.\nMonitoraggio delle Prestazioni: Pi-hole fornisce statistiche dettagliate sulle richieste DNS e sui domini bloccati, permettendo agli utenti di monitorare l’attività di rete e l’efficacia dei blocchi.\nInterfaccia Web: Il software è dotato di un’interfaccia utente web che semplifica la configurazione e la gestione. Attraverso questa interfaccia, gli utenti possono monitorare le statistiche, aggiornare liste di blocco e personalizzare le impostazioni.\nListe di Blocco Personalizzabili: Pi-hole consente agli utenti di aggiungere o rimuovere domini dalle liste di blocco in base alle proprie preferenze e esigenze.\nSupporto per IPv6: Il software supporta IPv6, garantendo una copertura completa delle richieste DNS e dei blocchi su entrambi gli standard di indirizzamento IP.\nIntegrazione con DHCP: Pi-hole può fungere anche da server DHCP, semplificando ulteriormente la gestione degli indirizzi IP e la distribuzione delle configurazioni di rete.\nViste le caratteristiche non poteva mancare nella suite di servizi installati sul mio homelab, l’installazione di per sè é molto semplice infatti basterà eseguire un semplice script che vi auto guiderà nelle varie impostazioni\ncurl -sSL https://install.pi-hole.net | bash Io personalmente per ora l’ho installato su un raspberry Pi 3 dove sono già presenti le istanze di Nginx Proxy Manager e il container per la gestione del tunnel cloudflare, scriverò un’articolo specifico su questa macchina in futuro.\nVoi potete installarlo dove meglio credete, un server linux, un container docker o su una VM, up to you! La documentazione è molto chiara e completa per ogni dettaglio specifico non posso che invitarvi a leggerla cliccando QUI\nAttenzione è importante che il server abbia l’indirizzo IP statico, questo non dovrà cambiare mai perché verrà chiamato da tutti gli altri device, se avete il DHCP attivo basterà impostare una reservation.\nEcco l\u0026rsquo;aspetto che ha la comodissima interfaccia WEB Oltre a liberami dalla pubblicità Pi-Hole mi è stato utilissimo anche come DNS locale per il mio homelab\nPer completare il tutto non dovete fare altro che modificare i parametri network sui vostri device facendo in modo che il DNS utilizzato sia l’IP della vostra installazione Pi-Hole, in questo modo ogni richiesta verrà gestita da Pi-Hole e addio alla pubblicità!\nPer chi ne avesse la possibilità la modifica DNS si potrebbe eseguire già a livello del vostro router, basterà editare una sola volta sull’apparato per avere così di conseguenza tutti i device già configurati.\nEvviva l’opensource!\n","permalink":"https://marcofanuntza.it/2024/01/06/grazie-pihole-basta-pubblicita/","summary":"Quanto vi infastidiscono gli annunci pubblicitari navigando sul web? Ormai ci sono pagine web piene di annunci, pop-up fastidiosissimi che non fanno altro che farci perdere tempo e voglia di visitarne il sito, i quotidiani con le news e le notizie sportive su tutti sono i più scassa bit.\nPer fortuna ci viene in aiuto Pi-Hole!\nPi-hole è un software open-source progettato per il controllo e la gestione della rete orientato nello specifico proprio per combattere la pubblicità e gli annunci correlati, sostanzialmente agisce come un filtro DNS, offrendo funzionalità avanzate per bloccare tutti gli annunci pubblicitari, tracker e tutti i contenuti indesiderati ancor prima che raggiungano i nostri dispositivi connessi alla rete.","title":"Grazie a Pi-Hole basta con la pubblicità!"},{"content":"Acquistai il mio primo NAS nel lontano 2011, uno Zyxel NSA320 che nonostante tutto funziona ancora ma il peso degli anni si sente tutto, è ormai fuori supporto da tempo, nessuna opzione per upgrade o mod varie, versione tls obsoleta e opzioni su share NFS inesistenti. Quest’ultimo aspetto mi sta dando problemi con i backup dei container che ho su Proxmox e per questo ho preso la decisione… nuovo NAS sia!\nIl primo aspetto preso in considerazione è: pappa pronta acquistando un prodotto commerciale dove basta inserire i dischi accendere e via, oppure costruirmelo da me?\nDevo ammettere che i nuovi NAS in commercio hanno tutta una serie di features veramente interessanti, sono praticamente dei mini computer e oltre a salvare i dati permettono di installarci vari servizi, il famoso Synology DS220+ ad esempio può essere un nas, un mediacenter, un reverse proxy, erogare virtual machines, erogare container docker, con questi ultimi due aspetti praticamente può fornire molteplici servizi, chi più ne ha più ne metta.\nTutto questo però ovviamente ha un costo (alto a mio avviso) e altro aspetto da tenere in conto è che la maggior parte delle volte dovete aggiungerci i dischi, money! cantavano i Pink Floyd.\nLa mia curiosità batte la pigrizia della pappa pronta, quindi ho optato per costruirmelo da me, poi diciamocelo chiaro il bello è proprio quello! e un articolo descrivendo quanto fosse bello il Synology non l’avrei poi mai scritto.\nLa scelta è semplice, trovare un vecchio desktop pc, uno di quelli SFF (small form factor), su ebay e amazon ne trovate a bizzeffe ricondizionati, garantiscono prestazioni adeguate e consumi ridotti considerando che un NAS dovrebbe rimanere acceso H24.\nTra i tanti modelli, dopo varie analisi, la mia scelta è ricaduta su un Dell OPTIPLEX 3050 SFF, quello che ho trovato io ha una cpu non troppo vecchia Intel i3-7100, 8GB di ram DDR4 espandibile e aspetto scatenante la scelta è la presenza di uno slot M2 per storage nvme, dove ci andrà installato l’OS.\nOk abbiamo la macchina, l’altra decisione da prendere è: che tipo di dischi utilizzare? le opzioni sono due, dischi super performanti SSD oppure classici e intramontabili HDD rotativi. Il prezzo dei dischi SSD è sceso tanto negli ultimi anni, ormai sono de facto i dischi da utilizzare su workstation e notebook, non sarebbero male da utilizzare anche sui NAS, c’è però un ma, i dischi SSD hanno una data di “scadenza” in base data dal numero di scritture eseguite, a questo si aggiunge un’aspetto che scoprirete dopo relativo al filesystem che verrà utilizzato ZFS, che per come funziona andrà sicuramente ad accorciarne ulteriormente la loro longevità.\nQuindi si la mia scelta è stata… HDD rotativi! e saranno da 2,5 più facili da inserire dentro alla macchina SFF e meno energivori rispetto agli HDD classici da 3,5 pollici.\nInfine arriva il software da utilizzare, scelta già fatta come avrete intuito dal titolo stesso dell’articolo, Truenas CORE sarà il software, il cuore e la mente del mio nuovo (vecchio) NAS.\nTrueNAS in versione CORE è una piattaforma di storage open-source basata su FreeBSD, progettata per fornire soluzioni di storage e condivisione di dati scalabili e affidabili. Originariamente conosciuta come FreeNAS, TrueNAS è stata ribattezzata per riflettere la sua evoluzione e le sue funzionalità avanzate. Ecco alcune delle sue caratteristiche principali:\nStorage Unificato: Supporta protocolli come SMB/CIFS, NFS, AFP, iSCSI, S3 e altri, consentendo la centralizzazione della gestione dei dati e l’accesso da diversi sistemi operativi. ZFS File System: Utilizza il file system ZFS, noto per la sua robustezza, gestione avanzata dei dati e funzionalità di snapshot e clone. Virtualizzazione e Containerization: Fornisce funzionalità di virtualizzazione e containerization con supporto per VMware, Hyper-V, Bhyve e Docker. Ridondanza e Alta Disponibilità: Offre opzioni avanzate per la ridondanza e l’alta disponibilità, garantendo la continuità degli accessi ai dati e proteggendo da guasti hardware. Sistema di Archiviazione Condiviso: Configurabile come un sistema di archiviazione condiviso in reti aziendali, consentendo a diversi utenti di accedere e condividere dati in modo sicuro. Backup e Ripristino: Include funzionalità di backup e ripristino, consentendo la creazione di snapshot e la pianificazione di backup automatici per garantire la sicurezza dei dati. Interfaccia Web Intuitiva: Dispone di un’interfaccia web intuitiva che semplifica la gestione e la configurazione del sistema, rendendo accessibili molte funzionalità avanzate. TrueNAS CORE e TrueNAS SCALE sono due varianti della piattaforma di storage TrueNAS, entrambe sviluppate da iXsystems. Ecco alcune differenze chiave tra i due:\nTrueNAS CORE:\nFile System ZFS: TrueNAS CORE sfrutta il file system ZFS per avanzate funzionalità di gestione dati, snapshot e resistenza ai guasti. Stabilità e Affidabilità: È noto per la sua stabilità e affidabilità, consigliato per utilizzi in ambienti critici. Orientato agli Utenti Esperti: TrueNAS CORE è più indicato per utenti esperti e amministratori di sistema che desiderano maggiore controllo sulla configurazione. TrueNAS SCALE:\nBasato su Debian: TrueNAS SCALE ha una base Debian Linux, offrendo maggiore flessibilità nell’integrazione con software basato su Linux. Architettura più Moderna: Progettato con un’architettura moderna e scalabile, adatto a carichi di lavoro su larga scala. Interfaccia Kubernetes: TrueNAS SCALE presenta un’interfaccia Kubernetes nativa, semplificando l’implementazione e la gestione di applicazioni in contenitori. Approccio All-in-One: Pensato come soluzione all-in-one con un modello di implementazione semplificato, adatto anche a utenti meno esperti. App Store: TrueNAS SCALE include un App Store integrato con una varietà di applicazioni e servizi aggiuntivi facilmente installabili e gestibili. In breve, mentre TrueNAS CORE offre stabilità consolidata e controllo avanzato, TrueNAS SCALE si orienta verso una flessibilità moderna, con facilità d’uso e integrazione di Kubernetes. La scelta tra i due dipende dalle esigenze specifiche dell’utente e dell’ambiente.\nIo avendo già un homelab con Proxmox, non ho l’esigenza di avere un ulteriore ambiente che sarebbe stato una sorta di “doppione” con Truenas in versione SCALE e poi a me serve un NAS.\nA questo punto dovrei mostrarvi il risultato…… si però dovrete attendere che mi arrivino i componenti!\nCome diceva il grande JeeG Robot “Miwa lanciami i componenti!”\nEcco clicca QUI per la seconda parte dell\u0026rsquo;articolo\n","permalink":"https://marcofanuntza.it/2024/01/01/il-mio-nuovo-nas-con-truenas/","summary":"Acquistai il mio primo NAS nel lontano 2011, uno Zyxel NSA320 che nonostante tutto funziona ancora ma il peso degli anni si sente tutto, è ormai fuori supporto da tempo, nessuna opzione per upgrade o mod varie, versione tls obsoleta e opzioni su share NFS inesistenti. Quest’ultimo aspetto mi sta dando problemi con i backup dei container che ho su Proxmox e per questo ho preso la decisione… nuovo NAS sia!","title":"Il mio nuovo NAS con Truenas"},{"content":"Problema\nAbbiamo dimenticato la password di un container LXC in esecuzione su Proxmox e non abbiamo alternative se non quella di resettarla.\nSoluzione\n*Effettuare l’accesso sulla web GUI del vostro cluster Proxmox.\n*Individuate il container LXC per il quale si desidera reimpostare la password e ricordarsi l’ID del container. Ad esempio, se vediamo un container chiamato:\n105 (passwdDimenticata) *105 saràil suo ID, passwdDimenticata sarà il suo nome.\n*Avviare il container nel caso non lo fosse già\n*Ora connettersi via SSH sull’host di Proxmox che sta eseguendo il container (come utente root) o aprite una Shell/Console sulla web GUI di Proxmox, sempre sul nodo che sta eseguendo il container\n*Utilizzare il seguente comando per collegare la sessione al container LXC\nlxc-attach -n 105 *A questo punto ci troveremo all’interno della shell del container e potremo eseguire i comandi, nello specifico per cambiare la password di root\npasswd *Digitare la nuova password, premere il tasto Invio, quindi digitare nuovamente la password e premere nuovamente Invio per confermare la nuova password di root del container. -Un a volta completato, è possibile effettuare l’accesso al container con la nuova password.\n","permalink":"https://marcofanuntza.it/2023/12/31/come-reimpostare-la-password-root-in-un-container-lxc-su-proxmox-ve/","summary":"Problema\nAbbiamo dimenticato la password di un container LXC in esecuzione su Proxmox e non abbiamo alternative se non quella di resettarla.\nSoluzione\n*Effettuare l’accesso sulla web GUI del vostro cluster Proxmox.\n*Individuate il container LXC per il quale si desidera reimpostare la password e ricordarsi l’ID del container. Ad esempio, se vediamo un container chiamato:\n105 (passwdDimenticata) *105 saràil suo ID, passwdDimenticata sarà il suo nome.\n*Avviare il container nel caso non lo fosse già","title":"Come reimpostare la password root in un container LXC su Proxmox VE"},{"content":"Spesso può capitare la necessità di dover ridimensionare il disco di un container creato troppo grande o relativamente piccolo, a dire la verità spesso si tende ad aumentare lo spazio disco, vuoi crescita dei logs, aggiunta di nuove funzioni, in questo caso specifico però mostreremo come ridurre lo spazio.\nPer chi come me utilizza Proxmox in ambito domestico dovrà fare subito i conti con la mancanza di una LAN a 10GbE, questo si tradurrà in migrazioni tra i nodi eccessivamente lunghe, la regola quindi deve essere: container piccolo = veloce. Quando si crea un container può succedere di non aver ben chiaro in mente quanto dimensionare lo spazio disco, ma niente paura si ridimensiona!\nProxmox di default quando crea il container utilizza LVM che sta per (in lingua inglese logical volume manager) in italiano gestore logico dei volumi, ringraziamo quindi questa scelta perché ci permetterà di ridimensionare i nostri container con dei semplici passaggi che scopo di questo articolo vi elencherò qui di seguito.\nPrima di tutto come sempre vi consiglio di eseguire un backup del container interessato, terminato il backup saremo pronti a partire.\nPer i comandi che seguono sarà necessario operare da \u0026gt;_Shell, la potete attivare da Proxmox e sarà sul nodo che in quel momento sta eseguendo il container interessato. Io personalmente preferisco operare direttamente da shell ssh ma sarà uguale.\nIniziamo con individuare il volume utilizzato dal container eseguendo questo comando:\nlvdisplay | grep \u0026quot;LV Path\\|LV Size\u0026quot; il risultato sarà simile al seguente; simile non uguale sia ben chiaro 😉\nLV Size 141.23 GiB LV Path /dev/pve/swap LV Size 8.00 GiB LV Path /dev/pve/root LV Size 69.37 GiB LV Path /dev/pve/vm-101-disk-0 LV Size 22.00 GiB dovrete prestare attenzione alle ultime due righe, queste infatti si riferiscono al disco (volume) del container che andremo a modificare, che potete intuire sarà vm-101-disk-0 sul percorso /dev/pve/vm-101-disk-0\nintanto procediamo con spegnere il container, si scusate non lo avevo ancora scritto, queste operazioni vanno eseguite con il container spento, eseguite il comando seguente per spegnere il container\npct stop 101 adesso partiamo con ridimensionare il filesystem del volume, nel nostro caso intento è di farlo diventare da 10GB quindi eseguiamo:\nresize2fs /dev/pve/vm-101-disk-0 10G il risultato ci restituirà:\nresize2fs 1.47.0 (5-Feb-2023) Resizing the filesystem on /dev/pve/vm-101-disk-0 to 2621440 (4k) blocks. The filesystem on /dev/pve/vm-101-disk-0 is now 2621440 (4k) blocks long. a questo punto siamo pronti con il comando che effettivamente ridimensionerà il nostro volume, il comando lvreduce fa parte della suite messa a disposizione da LVM, per i più curiosi c’è sempre il MAN di linux per approfondimenti, che detto in Sardo “mai ammanchidi” (mai manchi)\nlvreduce -L 10G /dev/pve/vm-101-disk-0 WARNING: Reducing active logical volume to 10.00 GiB. THIS MAY DESTROY YOUR DATA (filesystem etc.) Do you really want to reduce pve/vm-101-disk-0? y/n]: y confermate con “y” senza paura! avevate fatto il backup si? Il risultato che restituirà il comando sarà il seguente:\nSize of logical volume pve/vm-101-disk-0 changed from 22.00 GiB (5632 extents) to 10.00 GiB (2560 extents). Logical volume pve/vm-101-disk-0 successfully resized. le operazioni a questo punto sono praticamente completate, ma manca un ultimo piccolo passaggio e sarà relativo alla modifica della configurazione del container, dobbiamo semplicemente fargli sapere che le dimensioni del disco sono cambiate\nvi /etc/pve/lxc/101.conf la stringa rootfs dovrà cambiare semplicemente da 22GB a 10GB nel punto “size”\nrootfs: local-lvm:vm-101-disk-0,size=10G ora potete finalmente accendere il container e per avere la certezza della buona riuscita procedete con accedere nel vostro container su console e verificate lo spazio disco con un semplice df -h\nQuesto è tutto, il ridimensionamento è possibile anche in caso contrario, quindi aggiungendo spazio disco, il comando in quel caso sarà lvextend +10G e resize2fs ma comunque sia Proxmox in quel caso vi viene in aiuto permettendovi di eseguirlo direttamente da gui e completamente automizzato.\n","permalink":"https://marcofanuntza.it/2023/12/17/ridimensionare-disco-container-su-proxmox/","summary":"Spesso può capitare la necessità di dover ridimensionare il disco di un container creato troppo grande o relativamente piccolo, a dire la verità spesso si tende ad aumentare lo spazio disco, vuoi crescita dei logs, aggiunta di nuove funzioni, in questo caso specifico però mostreremo come ridurre lo spazio.\nPer chi come me utilizza Proxmox in ambito domestico dovrà fare subito i conti con la mancanza di una LAN a 10GbE, questo si tradurrà in migrazioni tra i nodi eccessivamente lunghe, la regola quindi deve essere: container piccolo = veloce.","title":"Ridimensionare disco container su Proxmox"},{"content":"Introduzione:\nNel corso della mia esperienza nel settore dell’IT, se c’è qualcosa che ho imparato è che l’efficienza e la flessibilità sono fondamentali. È qui che entra in gioco Proxmox, una piattaforma che ho scoperto essere un vero game-changer. In questo primo articolo, voglio condividere la mia esperienza con Proxmox e negli articoli che seguiranno mostrarvi come ho configurato il mio “homedatacenter”.\nChe cos’è Proxmox?\nè una piattaforma di virtualizzazione, un hypervisor di tipo 1 permette di virtualizzare virtual machine e container interfaccia web per il controllo permette configurazione in cluster gestisce storage, snapshot e backup automatizzati basata su Debian, utilizza KVM per le vm e LXC per i container completamente free e open source piani di licenza enterprise attivabili Virtualizzazione e Containerizzazione: La Combo Vincente\nAttraverso l’utilizzo di Proxmox, ho scoperto il potenziale di KVM (Kernel-based Virtual Machine) per una virtualizzazione performante delle VM e con LCX (Linux Containers) una rapida implementazione e gestione dei containers. La sinergia tra queste due tecnologie consente di raggiungere prestazioni elevate e un livello di efficienza senza precedenti.\nInterfaccia Web Intuitiva: Gestione a Portata di Click\nQuello che si apprezza subito di Proxmox è la sua interfaccia web user-friendly. Posso monitorare le risorse in tempo reale, eseguire facilmente operazioni di backup e ripristino. La gestione diventa un’esperienza visiva e accessibile anche ai meno esperti.\nBackup e Ripristino: La Sicurezza dei Miei Dati al Primo Posto\nProxmox garantisce una tranquillità in più con la sua robusta funzionalità di backup e ripristino. Creare snapshot delle VM e dei container è un gioco da ragazzi. In caso di necessità, il ripristino è veloce e indolore.\nCluster e Alta Disponibilità: Non Solo per le Aziende\nIl bello di Proxmox è che non è riservato solo alle grandi aziende. Anche nel mio ambiente domestico, ho potuto creare un cluster in alta affidabilità. La gestione centralizzata, la distribuzione automatica del carico e l’alta disponibilità delle risorse sono diventate una realtà anche nel mio piccolo “data center casalingo”.\nComunità Attiva e Supporto Professionale: Una Rete di Supporto a Portata di Mano\nUnirsi alla comunità Proxmox è stato un passo naturale. La condivisione di esperienze e il supporto degli sviluppatori e degli utenti sono inestimabili. E se mai avessi bisogno di un livello di assistenza più professionale, c’è il supporto dedicato per le esigenze aziendali.\nConclusioni:\nProxmox ha trasformato la mia gestione delle risorse server. Se stai cercando flessibilità, controllo e un’esperienza di gestione che si adatti alle tue esigenze, ti consiglio vivamente di dare un’occhiata a Proxmox. Sia che tu stia gestendo un ambiente aziendale complesso o stia creando un cluster nel tuo salotto, Proxmox offre un controllo senza precedenti sulle tue risorse server. Non potrei essere più soddisfatto della mia scelta.\n","permalink":"https://marcofanuntza.it/2023/12/16/gestione-home-datacenter-con-proxmox/","summary":"Introduzione:\nNel corso della mia esperienza nel settore dell’IT, se c’è qualcosa che ho imparato è che l’efficienza e la flessibilità sono fondamentali. È qui che entra in gioco Proxmox, una piattaforma che ho scoperto essere un vero game-changer. In questo primo articolo, voglio condividere la mia esperienza con Proxmox e negli articoli che seguiranno mostrarvi come ho configurato il mio “homedatacenter”.\nChe cos’è Proxmox?\nè una piattaforma di virtualizzazione, un hypervisor di tipo 1 permette di virtualizzare virtual machine e container interfaccia web per il controllo permette configurazione in cluster gestisce storage, snapshot e backup automatizzati basata su Debian, utilizza KVM per le vm e LXC per i container completamente free e open source piani di licenza enterprise attivabili Virtualizzazione e Containerizzazione: La Combo Vincente","title":"Gestione home datacenter con Proxmox"}]